{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlu-s2k9D1Ba"
      },
      "source": [
        "# Week 4: Transfer Learning, BERT (Homework)\n",
        "\n",
        "## Question Search Engine\n",
        "\n",
        "Embeddings are a good source of information for solving various tasks. For example, we can classify texts or find similar documents using their representations. We already know about word2vec, GloVe and fasttext, but they don't use context information from given text (only from contexts of source data).\n",
        "\n",
        "For today we will use full power of context-aware embeddings to find text duplicates!\n",
        "\n",
        "__Warning:__ this task assumes you have seen `seminar.ipynb`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYffoHiI8du5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc19ecc7-caca-4d17-8c71-3775cadf0f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.18.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from deepspeed) (13.590.44)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.18.3-py3-none-any.whl size=1770204 sha256=f3326dc4d89ad47d28bdc44618405bf9300198e41982de476aa388e04ffa72b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/9a/37/beb534d37a37cd057d48ba20b82f34d527816b7fdf0206882f\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, pyarrow, ninja, deepspeed, datasets, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 deepspeed-0.18.3 evaluate-0.4.6 hjson-3.1.0 ninja-1.13.0 pyarrow-22.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade transformers datasets accelerate deepspeed evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import datasets"
      ],
      "metadata": {
        "id": "DfnU-D052ta9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfSHyQlT-fVF"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_wgtrx8e6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "0818b871f0b84dcab50ebc1b32d77a48",
            "b8de657431454deebc8514303cbac56f",
            "7548dc34c93f48a194e2a1837816d893",
            "69337025500a4bf39807641a073b38df",
            "586b3b9e5484441ca8ffc04885b4d693",
            "e640b982f37a44c5ac26453373eb6304",
            "f455954a84ad49a78c998a076214c002",
            "f524172d756b4db5814b16b5d56e52f7",
            "fbd98be477bb4a1e966a88456d1c8214",
            "2da6121e85654505968375d9451f0019",
            "c762588fbd904c8884fe89eda1a59374",
            "ca16b0dc426a42b9b917565b772ed452",
            "161ebacdf0f844b9b65d6507ee095fda",
            "5c2ae3971d3d40daac355ff2c922e4d6",
            "ed2f9bf765d14368b42403348f8179c6",
            "aad1c4c099a5442299025ef107d83668",
            "06f9e82ad7784bd2b390892c690cb0a1",
            "58bd0af4177246e39e337a6a1f15ffbd",
            "63c3a091f21645cba876b046559311ee",
            "46c892cce446448a94afd6e6693e7ff7",
            "9080edb684a7454c84e795fe7118c625",
            "36373c4865cd47ac808012c4ab5f540a",
            "c252d0a0d9464a0fabd30cbceceeb341",
            "8fe22c50d9724d3484af84f8f2bcd78c",
            "f4404aa8073343c483222fd17455feea",
            "4f26ce0be1784488a8c9d2b1f96a6d81",
            "f7568995937e4a43a12449d8fe2eaaec",
            "b23de48623214e51a293b4734cfe0eeb",
            "bb60bf370179433e825f41f26149b456",
            "f29f133ba4ba47219d81409a04d90723",
            "3a03b73a2c424acba046fde02d272843",
            "e47a8fbe56c449dda8acb1393903d8f2",
            "2bce2d48234142888ec5970b01dff376",
            "38ed04edacfe48babdf5ba415f6e3681",
            "4fa4458744f9417684ee322a600ecbb6",
            "33fb2c38f9e64b3d956aec263b2af414",
            "b2a14a668ecc46ccbd1d5c13ee3a57dc",
            "b6449c4e25544bc5ae8e3236ebdbbd22",
            "f35f6465df1b4dab9fbd6f2d60877c17",
            "c224563c849b42e181ebad16a22327a3",
            "412277471ad04034bd65f4dabcc4ac54",
            "0df6477073e74a6ca39c248dbf2ff4a4",
            "2f489cd4c88e4c17bb24f5653c481f18",
            "9da7c6044f1649eba5e6386fb807f523",
            "89a33cdca3de4556ae9cb643596071ed",
            "4756bb1703524061b14f85df91ae71ca",
            "7abcd3f085a945b29982a9d14e092048",
            "a210c991ab8f43b981f921d87c52c826",
            "5847f079660942f5a76a918f308e3b1d",
            "2110747953394774b692bf0a57d6ba82",
            "74b56ebecf41410ab4c00aca2a031cc4",
            "61e2efbff1f040348b89305cbac3dd98",
            "7f601bcaf71c4838a42bef2c6c5f9acb",
            "ef8dd19fc013415a9f742237e0496466",
            "d306815c4a9c4608b5859864ae5a7161",
            "e970ad32196d4c8a93e5b5901b076284",
            "72e81245428447628d2d000b075c63c6",
            "1ade7017bb4a4e0b89e6b794df6a6e99",
            "8ba5f0348411400fbe604d7fb9d2c67d",
            "ac3f51a0f1f34f6cac3a91d98dc026d4",
            "f41e5106393d4a0281a9bfdee7a1ae82",
            "ccb25bcd26bc40d887e2add2aab4b03d",
            "20153dfd565d43fc8df12467622b5c56",
            "d9e0bf3623504649afd5a2cb2638ed32",
            "651a3ce0c22849e9acc5d5cc0f7c7334",
            "d78c0fe036444a03996c23b9eff0e323",
            "b9ec6647c9994d9dbb6543ef86aeea1f",
            "3bcf7ed9caa64bc2a6d11a3355686110",
            "d8e49036fc8c4039a4763171d7b5567a",
            "e1e6f68139b1445da4d9c5428ebfb833",
            "c769915f01bf45bdb3cbb3a562fc6234",
            "8607928499bb4ceaa42bfbae62ffc02b",
            "d3f6899a0ff040af9364aca42af6f7cf",
            "357f458840774312812be46e300c4a5f",
            "f3c3d0b1f7d84667899113c715d77bfc",
            "ddf36b1451a34ce58f4323ca6b17882d",
            "aef01a6b10e84afa9d58cab1b1b6eb69"
          ]
        },
        "outputId": "1a88bd2f-1220-41d9-8d90-21153c9d47ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0818b871f0b84dcab50ebc1b32d77a48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/70.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca16b0dc426a42b9b917565b772ed452"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c252d0a0d9464a0fabd30cbceceeb341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/76.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38ed04edacfe48babdf5ba415f6e3681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/363846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89a33cdca3de4556ae9cb643596071ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/40430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e970ad32196d4c8a93e5b5901b076284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/390965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ec6647c9994d9dbb6543ef86aeea1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sample[0]: {'text1': 'How is the life of a math student? Could you describe your own experiences?', 'text2': 'Which level of prepration is enough for the exam jlpt5?', 'label': 0, 'idx': 0, 'label_text': 'not duplicate'}\n",
            "Sample[3]: {'text1': 'What can one do after MBBS?', 'text2': 'What do i do after my MBBS ?', 'label': 1, 'idx': 3, 'label_text': 'duplicate'}\n"
          ]
        }
      ],
      "source": [
        "qqp = datasets.load_dataset(\"SetFit/qqp\")\n",
        "print(\"\\n\")\n",
        "print(\"Sample[0]:\", qqp[\"train\"][0])\n",
        "print(\"Sample[3]:\", qqp[\"train\"][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pStlWcvD8rdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "62ddd6a6f2fa4ff887d8b6fd4bbb0a77",
            "655a405aff7a4703b3f5f40f6c96590a",
            "56d58fccca7942dbbc57b1ea46d9ef06",
            "ae8bdd2c60d141ef96f62275f0aa4259",
            "08b278881d5e4aae88308ad972746332",
            "21365fc428c44f26a33f5513cdb86023",
            "bd302744f326457981d5540d19dd0f04",
            "eb958012e77c415b8ef2430056a27e16",
            "08b55c6ee6b2461fb5baa7124596f216",
            "19b7fb98cb51460088ad386910e31403",
            "213a03a757d341d2aeae2f55260d9880",
            "b4d6c31340c043c18790ed1cc8742b9b",
            "20cf92ea67d94a16883350781cdd6ba2",
            "fe07475b99fc4c878671d42a1852a3d9",
            "dec32c51174847b5aea656086f15c4c2",
            "c0e8312435be42e89e98ea3dcaa6973f",
            "7e5efcc12158474588bb2ca14a8bd912",
            "ba435670ea874af3b7749a67509f10e4",
            "85116005d73d4b47ba8c021492731038",
            "96f3bb4a1a1d4931afcd27a4bdb2badb",
            "31686c4fca794a84a3c1b96146003714",
            "f7e025ed9f33430c94bae83531f77747",
            "387a208192474923beb23c45a769b8d8",
            "795a7cdfb46b4d09b25c69f73818df93",
            "974de1f342634bf9a09dd4c29f43ab64",
            "1a832ec3e21c40b5a0d90dc868bb7488",
            "3c685d55efbd426b980991dd0bfba260",
            "26b00acf02a64ecea5fb6bf8b189cd1c",
            "a1ff4c88b48e483894e8cde45fc65d82",
            "e65b91202dee4f8095b243cf2a34ad50",
            "f88788815cdd417f8bba08aee97d6709",
            "210490cd7c3e4167b4988c67c104c152",
            "487478e2f0584c80b9027b5bc20622b6",
            "51cef6f60c0747069f3fa923f55941a1",
            "a386f224d7ef4039804f741f7ff07b48",
            "4e73e571bd4141faba4304ad366ccd6f",
            "1454dfef50fe41d7a7790fa34e414821",
            "6512c6e74e3b4ad4a720c5e7f390f208",
            "d36275bd31f84801a0ce92ec7f27a694",
            "25b3cc94f0124f6b9d00067c0d46aa6e",
            "ff03f49f782d4fa6b0178d9f4f2e5dc6",
            "82f694ffcfaf4bdb856ddae8a8b87db1",
            "334d3f2a836249b39df8de3363bd8348",
            "378d49e77d3f466d8cc2c48c262cfa10",
            "b22f780caafa45329a127fd33c36cdfb",
            "efb2ef9c5aaf4566b11d990333cc303e",
            "4eeade766dab4def9aeb94488b30b386",
            "34724f7adf7842a9b2fb0131000a5bd0",
            "ac2f1545c68341a79fdcf193f6e41bf4",
            "be5f10da853f4ccab1a01742af4880fd",
            "33369cc8deb84090b8767b1fb28fcd4b",
            "f6139213c20040dc8d5125db20b093d7",
            "1bd9b6f2f04044c58e2ad22d86b7a602",
            "3a476e4289c34b86816bb9f14bee31ea",
            "83fa3da5ed824579badda22bc17c3fee",
            "fe2fadcf981c422d89aec4aa4fb6a164",
            "f2f7fac996584c108aa89db2c5876c75",
            "8163b2f58fe04582aeabeb62658b0afd",
            "02a133d7e5b54f7a80c5f860fd9a3cd3",
            "101033832e6641e2940452dc9f5e75cd",
            "b11f2088d055465cb02b02d9f686f19b",
            "c57cf52a2ccb48e0a47a0994dbb8d300",
            "f891762ab77042dcaf2ca65a3d9fc069",
            "326802df009346a19f161df1abee128c",
            "70df48a5159449dbabcd62003d334483",
            "e2f0793dd137454db8e48e17004a97b7"
          ]
        },
        "outputId": "f403f29b-ecfc-4eca-9b2e-995aee02d67d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62ddd6a6f2fa4ff887d8b6fd4bbb0a77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d6c31340c043c18790ed1cc8742b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "387a208192474923beb23c45a769b8d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51cef6f60c0747069f3fa923f55941a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b22f780caafa45329a127fd33c36cdfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe2fadcf981c422d89aec4aa4fb6a164"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtkllSPG9bTL"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    result = tokenizer(\n",
        "        examples[\"text1\"],\n",
        "        examples[\"text2\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    result[\"label\"] = examples[\"label\"]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HdPHQe4RmWs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "193ed4237c744e8ab8827b4b4ea9e68b",
            "b4159fba96244af283865f597375d514",
            "ba67ca5c0f874003b10f4d3d8f50371d",
            "85c62d7be6ef44d3b3c520b5e08e25b5",
            "9d05472d40414224b58db96a18d70b84",
            "3a6beb980e674ecd8e845254977f5d61",
            "79f499329b0144a8b33b2774f90790e9",
            "5e2c92ef55a34c3bae36287627e63cfc",
            "95abf90ac2a4425e9abdf2b74fae8c9b",
            "863e2ce3623c4706aa2ccb864b7b04bd",
            "baddc3b858b3405db456471bea439858",
            "aa067b3c3fc04f219d992b4f10e28298",
            "81a7945535d6497489b1b5a6f0810acc",
            "0c3e5929db8448eeb4359dd0a373d8ff",
            "7888658966104c8797c1bc45d793d251",
            "4d54634c615d44dfbc07c4883edfabbc",
            "0241954ff8fa40e08410c861dd58f466",
            "604895974e29445b9427d887b7b6142e",
            "76f5826d5e9b4ecf9f5552e510ea6cf5",
            "e145f5060c3640b0be2e289383589f97",
            "edddab5582e64af4beac76d4fee01a6c",
            "b2eb435e0e6a4a8ab6b66c81bb20831e",
            "fb7a716ccd6241169fa4704cffbdf7ac",
            "cb5b1aa4b0b64a00a4c3c90d94c518de",
            "20c9e9e7451e42fc8cc921d3ae50662c",
            "4a201a3d34994f72af54c60b97c8980d",
            "439dd1b5843341deab922fd258278ed1",
            "f370984d648449c7bb730408a9a852c1",
            "e3f8f39967064ce0a80053a609d6dbd7",
            "2b643169939e4f1a852f64159f25edb9",
            "28a1da0dbd8147e48bb4d2693c47fa35",
            "e0e4a65fee6f4e58bb2915714b268711",
            "d5c87e1aa75040768208655835d25f5a",
            "3552b3b33cfd43b8a484b30ffd2215b1",
            "cf0d3e49020d4196bb161acf5d508e80",
            "efd0ed7875284c55a3727b6441894d28",
            "f63e839d76d54ffdb7a2ecfd50fe17a3",
            "2b78359c10714c799ca3ca60f57de967",
            "a98e60811a7c4aac808438762ec059b3",
            "34b642b7c1f64f67a7961bddab78038f",
            "7b5bd66c994942318c68762ef39c6508",
            "a8513e7ee0cb49d99b99c3a96f9732a2",
            "16e4209bbb0f4fa495e1662a274101d3",
            "3062c463ae8c443b9bc2659ac6edbc29"
          ]
        },
        "outputId": "3067c841-3bd2-4fa4-eac8-14f0f966a0b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/363846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "193ed4237c744e8ab8827b4b4ea9e68b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa067b3c3fc04f219d992b4f10e28298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb7a716ccd6241169fa4704cffbdf7ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3552b3b33cfd43b8a484b30ffd2215b1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "qqp_preprocessed = qqp.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObMcFN59_Ll2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c1d74f-64b6-4db6-9564-403296c27dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1731, 1110, 1103, 1297, 1104, 170, 12523, 2377, 136, 7426, 1128, 5594, 1240, 1319, 5758, 136,  ...\n"
          ]
        }
      ],
      "source": [
        "print(repr(qqp_preprocessed[\"train\"][0][\"input_ids\"])[:100], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyQ1ZbzGAUF2"
      },
      "source": [
        "### Evaluation (1 point)\n",
        "\n",
        "We randomly chose a model trained on QQP - but is it any good?\n",
        "\n",
        "One way to measure this is with validation accuracy - which is what you will implement next.\n",
        "\n",
        "Here's the interface to help you do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5ueSoieAbBg"
      },
      "outputs": [],
      "source": [
        "val_set = qqp_preprocessed[\"validation\"]\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=1, shuffle=False, collate_fn=transformers.default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsPwXXx-At-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e766a0d3-f14c-4f0b-cae7-1d71d4b93872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch: {'labels': tensor([0]), 'idx': tensor([0]), 'input_ids': tensor([[  101,  2009,  1132,  2170,   118,  4038,  1177,  2712,   136,   102,\n",
            "          2009,  1132,  1117, 10224,  4724,  1177,  2712,   136,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "\n",
            "Prediction (probs): [[9.99892712e-01 1.07280895e-04]]\n"
          ]
        }
      ],
      "source": [
        "for batch in val_loader:\n",
        "    break  # here be your training code\n",
        "print(\"Sample batch:\", batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted = model(\n",
        "        input_ids=batch[\"input_ids\"],\n",
        "        attention_mask=batch[\"attention_mask\"],\n",
        "        token_type_ids=batch[\"token_type_ids\"],\n",
        "    )\n",
        "\n",
        "print(\"\\nPrediction (probs):\", torch.softmax(predicted.logits, dim=1).data.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoxHzxn0DQqO"
      },
      "source": [
        "**Task 1 (1 point)**\n",
        "\n",
        "- Measure the validation accuracy of your model. Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
        "  - Run the model on GPU with no_grad\n",
        "  - Using batch size larger than 1\n",
        "  - Use optimize data loader with num_workers > 1\n",
        "  - (Optional) Use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lZ5IC9ebs_Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLEtqcT5tBx5",
        "outputId": "0c5fe66f-804a-4013-c800-c12dc45e3926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    qqp_preprocessed[\"validation\"],\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=default_data_collator,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        with torch.cuda.amp.autocast():  # mixed precision\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                token_type_ids=batch[\"token_type_ids\"],\n",
        "            )\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Validation accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiyXkSBDs69m",
        "outputId": "0ed63c0f-b2e0-40bf-dbf0-5d63158a5436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1264 [00:00<?, ?it/s]/tmp/ipython-input-1831878373.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # mixed precision\n",
            "100%|██████████| 1264/1264 [00:58<00:00, 21.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.9084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R2z_-FZU3qy"
      },
      "outputs": [],
      "source": [
        "assert 0.9 < accuracy < 0.91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KONQ1E0J-y6B"
      },
      "source": [
        "### Training (4 points)\n",
        "\n",
        "For this task, you have two options:\n",
        "\n",
        "__Option A:__ fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base). Better yet, choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
        "\n",
        "You can write the training code manually or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT.\n",
        "\n",
        "\n",
        "__Option B:__ compare at least 3 pre-finetuned models (in addition to the above BERT model). For each model, report (1) its accuracy, (2) its speed, measured in samples per second in your hardware setup and (3) its size in megabytes. Please take care to compare models in equal setting, e.g. same CPU / GPU. Compile your results into a table and write a short (~half-page on top of a table) report, summarizing your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHsPQwHUR3z7"
      },
      "source": [
        "**Task 2 (4 points)**\n",
        "- Choose Option A or Option B (only one will be graded)\n",
        "- Follow all the instructions and restrictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "import numpy as np\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "TDScpUqa2cl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "62d8650129244aefba2724dd2f460484",
            "f4a0820cae224847a778b4b2d9486235",
            "46e4c39d5e684eaa86d953f768de22f1",
            "a9220f1074e94539add0aff35d378a7d",
            "93be0ce9d17644d48a486a1cb52f3181",
            "db69013ab2824594a3c330a6ddc7a8df",
            "c651d6ad4d544a8e94881dc3fb3bb223",
            "5f10ae3d248d44c4a73a4f5a728b1ce2",
            "bd15ca1084bc4ccc96785bf61fa46a67",
            "4871058f7bb8437a9cc4cf97dd26c603",
            "d65c24d1983b46a0be46c0e1e7a42f92",
            "76d35e3037d34697b736e3dccfb3c5a1",
            "bdb985d12c464c168141d8df3c6c01b0",
            "9839a9a9e7da40f09c31c8c79fa7e6d4",
            "71b038b3f8244cbaac457f8d239c0362",
            "64b918d5bed94bc99e67eec9223739ba",
            "c24fccdd3d5741ba969f062e3374b5a5",
            "90133f5cc9584adcb740dc7bef646eea",
            "df32754ef8764cccbc8f4f185311ff55",
            "789f9f1c2189403684e3dac864ae7a36",
            "1f13f238aa074af4b23f06ac8b2efee8",
            "cb2efed67d6f4c8980303713711bfe6d",
            "16b43ffd805c498b87e7d584ce737898",
            "45020d70d0b94d7a80ca29660ef56d6d",
            "d89f2f7fc11142619918098b3a44c7b7",
            "028049a79a924420b5a3fe605b1f2119",
            "6e0f7acd63da42c88899db8be3f3fefb",
            "b6ad0d8a6fdb49f6a9cd43f150dc7e32",
            "9fb138f40a2d402883dda41461f56c53",
            "8216403af7fb435a9b1d914837040215",
            "04b9f469cb004165acfb195c6df95f3f",
            "22dc0a6ab51b4f109025d4371a049d0d",
            "a1a78e6a2cfa4640ab94eec6896396f8",
            "3d3691b888de4b0197f35f676ffddfe4",
            "5326b9ec50d54137bda888ccb1d92313",
            "2b43053b4317492384e901f478f93dec",
            "ffaf29bfa0db4cd19ba8c97a1f825f5f",
            "fac85b8c43384f139bcbbb648d0911af",
            "4926a109d13540e7b2ebe39272c30a9f",
            "43a21ccbafb1486ba22a663156718571",
            "91fe0785c6d84ce68cec5c7e4c32ee5e",
            "178033f1a79c4bb995519df4c2a0dcda",
            "6821ca525db043f384550a983ddd64f6",
            "339f51bc25bf4f76b48a514440e2d74c"
          ]
        },
        "id": "idGcU_Xn2yN3",
        "outputId": "c4e031bf-d261-4077-efae-65df1d6b64f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d8650129244aefba2724dd2f460484"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76d35e3037d34697b736e3dccfb3c5a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16b43ffd805c498b87e7d584ce737898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d3691b888de4b0197f35f676ffddfe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    result = tokenizer(\n",
        "        examples[\"text1\"],\n",
        "        examples[\"text2\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH,\n",
        "    )\n",
        "    result[\"labels\"] = examples[\"label\"]\n",
        "    return result"
      ],
      "metadata": {
        "id": "G1Cmdcjq24ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qqp_preprocessed = qqp.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=qqp[\"train\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d0c8d9ef5f4844d9aeee73490a06318b",
            "723a2924b96843eb8afc63d410b5a57d",
            "b249bd917b1e4796b293bd15bcdc574e",
            "a3072537b83f45f492190fc807a2bc6b",
            "4dedcb26658c4a8fa8e4158826b15284",
            "3c5c9dfe8ab1423e87d95ca37acd2b85",
            "12a14c51335b4980ba92ee35ace63def",
            "3ac702ed18eb46f1b84ca9b8da3dac06",
            "8b20e3565c9b4858bd5343ac11cc59b8",
            "dab2452678054b438910eff96d86899a",
            "13ee8eadd2014d35873c3906bbf9a11a",
            "fc69a398901d40d8a3c25c06349b2ea7",
            "7746e04211934e3d85b56b8970b58585",
            "e9cb56a42e33450cbfbb03951b745816",
            "b21de0e8201a4fb083e18edabea04919",
            "1f829842bf9b4e1695848757f47bcc71",
            "9e2884277f88426db1d95ce124fa620e",
            "12722ebf136f457896ce61e251f6abab",
            "617783da1aa4419cb8bd0354336693e9",
            "9297a6adca8c4be6ac45d1edd314c580",
            "040fe3bbadfb4234b4d2db64c7b7c07e",
            "87716d86bba54c00a6984ba9e4e978d5",
            "57d57934e1394007aff81e8a8b45b2bc",
            "cdbaf29f92e14462b8ec29889c20cdc5",
            "1fb0a1194d694fc4b11ba1eb0a17b748",
            "6f1a01b80d504ce58d68721e1c66d2a0",
            "8dfc4b12f5564c7ab51e9d95b19e3965",
            "7a94c3689bf944dbae077a1c1c7bc5ed",
            "72975c1605584233ab06a995705aafaa",
            "ae00bf213d404288b655bd3dba4809b1",
            "70cca2ada56044ab8b967752e34114a3",
            "e822b36296e44cd2b7b7b13c81b00f0d",
            "adc4ca85ef60415da6fc8ef7c742fcaf",
            "4541e0bb0c824acbb974e4fb8216ee31",
            "fb6253f6b8404386a63e6f0c995d4236",
            "764bf31a655c42e689c1d60f815f8d8a",
            "bffd1a78cfb84b83b000c22792711778",
            "93f7de784ae94a3597b6acbc2fd2d5e7",
            "21c8c99251294c3397d986069a10d047",
            "9cedb95cd8eb41dabb7f3d01f892dde7",
            "1f0c245a402a4ee8b40bdd728d0d820d",
            "92ccc8cc41494aa6827037e3d172fc50",
            "7756a30ed4a04b039a33311084050a1c",
            "0e20d08dff2c4f6e8675431ee9d312d5"
          ]
        },
        "id": "k_40KuoU28Aj",
        "outputId": "d864f1a4-b5a0-4992-9d89-cac2535d929b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/363846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c8d9ef5f4844d9aeee73490a06318b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc69a398901d40d8a3c25c06349b2ea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57d57934e1394007aff81e8a8b45b2bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4541e0bb0c824acbb974e4fb8216ee31"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return accuracy_metric.compute(predictions=preds, references=labels)"
      ],
      "metadata": {
        "id": "j1e2Bi8J2_E5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06d8a8f393d748d6bb54a91ee1dbbc63",
            "3c3c4efbc0f84f8083631b09a1ab0f1b",
            "200fce060cb74c91b8b6f8b01254663f",
            "504748aab8da43798365e06d73715bf5",
            "b25130a4a7b24a53a578a44569c73831",
            "efe60914120d4f2dbb1352a644bb9930",
            "642266abbac248a1a28d0df148472f31",
            "3fd25a8d0a8843f6a4224842f925c218",
            "7d5b2e922b2d459eaaab87ef44c145c7",
            "0b1fdb520330469ab0333240124403a1",
            "6a90768ec7b74dff99679835a19ec01e"
          ]
        },
        "outputId": "5bb0718c-0705-4010-d876-c334a6780d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06d8a8f393d748d6bb54a91ee1dbbc63"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./deberta_qqp\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=200,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "WKsBoFaK5yXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=qqp_preprocessed[\"train\"],\n",
        "    eval_dataset=qqp_preprocessed[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RNudcO3F5a",
        "outputId": "e32e6717-ef49-4e47-b237-5d11c4e78f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3811660937.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "IFuayv_i3I2t",
        "outputId": "5a3c7c86-19f6-4b76-faec-c23dd10d96a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='45482' max='45482' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [45482/45482 2:34:49, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.227700</td>\n",
              "      <td>0.215811</td>\n",
              "      <td>0.916597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.156400</td>\n",
              "      <td>0.234213</td>\n",
              "      <td>0.922236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=45482, training_loss=0.21304309624469425, metrics={'train_runtime': 9290.8341, 'train_samples_per_second': 78.324, 'train_steps_per_second': 4.895, 'total_flos': 4.78668109446697e+16, 'train_loss': 0.21304309624469425, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(\"Validation accuracy:\", eval_results[\"eval_accuracy\"])"
      ],
      "metadata": {
        "id": "lx4dyVpz3Jh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "592cc08a-d5a9-4af9-e6bd-b8e710e0aad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1264/1264 02:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.9222359633935197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQD0IV44LrSs"
      },
      "source": [
        "### Finding Duplicates (1 point)\n",
        "\n",
        "Finally, it is time to use your model to find duplicate questions.\n",
        "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
        "\n",
        "Showcase how your function works with at least 5 examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM5WXW8hSl7H"
      },
      "source": [
        "**Task 3 (1 point)**\n",
        "- Implement function for finding duplicates\n",
        "- Test it on several examples (at least 5)\n",
        "- Check suggested duplicates and make a conclusion about model correctness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "def get_embedding(question):\n",
        "    inputs = tokenizer(\n",
        "        question,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.base_model(**inputs)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    return cls_embedding.squeeze(0)"
      ],
      "metadata": {
        "id": "fYkCzydNAMPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions = qqp[\"train\"][\"text1\"][:70000]\n",
        "train_embeddings = []\n",
        "\n",
        "for q in train_questions:\n",
        "    emb = get_embedding(q)\n",
        "    train_embeddings.append(emb)\n",
        "\n",
        "train_embeddings = torch.stack(train_embeddings)"
      ],
      "metadata": {
        "id": "YTgq5XZAvSlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_duplicates(question, top_k=5):\n",
        "    query_emb = get_embedding(question)\n",
        "\n",
        "    similarities = F.cosine_similarity(\n",
        "        query_emb.unsqueeze(0),\n",
        "        train_embeddings\n",
        "    )\n",
        "\n",
        "    top_indices = torch.topk(similarities, top_k).indices\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"question\": train_questions[idx.item()],\n",
        "            \"similarity\": similarities[idx].item()\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "En1VFNgC_-b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"How can I learn machine learning?\",\n",
        "    \"What is the best way to lose weight?\",\n",
        "    \"How to prepare for job interviews?\",\n",
        "    \"What is Python used for?\",\n",
        "    \"How can I improve my English?\"\n",
        "]\n",
        "\n",
        "# Ensure train_embeddings is a tensor before calling find_duplicates\n",
        "if isinstance(train_embeddings, list):\n",
        "    train_embeddings = torch.stack(train_embeddings).to(device)\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\nQuery: {q}\")\n",
        "    results = find_duplicates(q)\n",
        "\n",
        "    for r in results:\n",
        "        print(f\"  - {r['question']} (sim={r['similarity']:.3f})\")"
      ],
      "metadata": {
        "id": "S_jDRyU9__Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cfd82f-796d-4142-c2d3-7678bce35eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: How can I learn machine learning?\n",
            "  - How can I learn machine learning? (sim=1.000)\n",
            "  - How can I learn machine learning? (sim=1.000)\n",
            "  - How do I learn machine learning? (sim=0.999)\n",
            "  - How do I learn machine learning? (sim=0.999)\n",
            "  - How do I learn machine learning? (sim=0.999)\n",
            "\n",
            "Query: What is the best way to lose weight?\n",
            "  - What are the best ways to lose weight? (sim=1.000)\n",
            "  - What are the best ways to lose weight? (sim=1.000)\n",
            "  - What are the best ways to lose weight? (sim=1.000)\n",
            "  - What are the best ways to lose weight? (sim=1.000)\n",
            "  - What are the best ways to lose weight? (sim=1.000)\n",
            "\n",
            "Query: How to prepare for job interviews?\n",
            "  - How should I prepare for a job interview? (sim=0.999)\n",
            "  - How do you prepare for a job interview? (sim=0.999)\n",
            "  - How do I prepare for an engineering job interview? (sim=0.998)\n",
            "  - What are the best ways to prioritize a list of product features? (sim=0.997)\n",
            "  - What are the best ways to prioritize a list of product features? (sim=0.997)\n",
            "\n",
            "Query: What is Python used for?\n",
            "  - What can Python do? (sim=0.999)\n",
            "  - What is JavaScript used for? (sim=0.998)\n",
            "  - What are logarithms used for? (sim=0.998)\n",
            "  - What are macros in C? (sim=0.998)\n",
            "  - What do stalkers do? (sim=0.998)\n",
            "\n",
            "Query: How can I improve my English?\n",
            "  - How could I improve my English? (sim=1.000)\n",
            "  - How could I improve my English? (sim=1.000)\n",
            "  - How could I improve my English? (sim=1.000)\n",
            "  - How could I improve my English? (sim=1.000)\n",
            "  - Who can help me improve my English? (sim=0.999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RIdHp6TaZY"
      },
      "source": [
        "### Bonus: Finding Duplicates Faster (0.5 point)\n",
        "\n",
        "Try to find a way to run the function faster than just passing over all questions in a loop. For isntance, you can form a short-list of potential candidates using a cheaper method, and then run your tranformer on that short list. If you opted for this solution, please keep both the original implementation and the optimized one - and explain briefly what is the difference there.\n",
        "\n",
        "**Bonus Task 1 (0.5 point)**\n",
        "- Speed up your implementation from \"Finding Duplicates\" part\n",
        "- Capture both old and new implementation work time\n",
        "- Describe your approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V49F_ZyaUTSx"
      },
      "outputs": [],
      "source": [
        "<A whole lot of YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzJFS5v5UTtz"
      },
      "source": [
        "### Bonus: Finding Duplicates in Old-Fashioned way (1.5 points)\n",
        "\n",
        "In this bonus task you are supposed to use pretrained embeddings (word2vec, GloVe or fasttext) for solving the duplicates problem.\n",
        "\n",
        "**Bonus Task 2 (1.5 points)**\n",
        "- Solve Finding Duplicates problem using mentioned embeddings\n",
        "- Compare old-fashioned solution to previous ones (quality, speed, etc.)\n",
        "- Make a small report (up to 5 steps, results and conclusions) on work done in this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2HjQwr_Vvu6"
      },
      "outputs": [],
      "source": [
        "<A whole lot of YOUR CODE HERE>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}